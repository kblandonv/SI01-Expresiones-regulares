{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vw4vyHJgIWfA"
      },
      "source": [
        "##«*Mira y escucha. Una rosa tiembla, agitada por la brisa, y el ruiseñor le canta un himno apasionado*».\n",
        "###[Omar Khayyam](https://en.wikipedia.org/wiki/Omar_Khayyam)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dgqyju__IQ2K"
      },
      "source": [
        "# SI01 Expresiones regulares\n",
        "\n",
        "Resuelva los siguientes ejercicios con códigos que se ajusten al PEP8. Recuerde incluir los comentarios en el código y documentar las funciones con docstrings al estilo de Google.\n",
        "\n",
        "**Descargue de [archivos datos regex](https://github.com/gabrielawad/talleresGoogleColab/tree/main/Archivo_datos/regex) el que corresponda con su número de documento de identidad**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rP2Y7el2JAp5"
      },
      "source": [
        "# Preparación del ejercicio\n",
        "\n",
        "*   Importe las librerías requeridas\n",
        "*   Lea el dataset a utilizar desde una url\n",
        "\n",
        "**Sugerencia**: suba el dataset a un repositorio de GitHub, o al Googledrive **de su cuenta personal de gmail** y luego publíquelo en la web como un archivo *.csv. El siguiente enlace le indica cómo hacerlo: [Cómo publicar archivos de Documentos, Hojas de cálculo, Presentaciones y Formularios de Google](https://support.google.com/docs/answer/183965?hl=es-419&co=GENIE.Platform%3DDesktop).\n",
        "\n",
        "Nota: si lo desea puede utilizar otro método para obtener la url del dataset.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "WDXlcxw2LUl5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset cargado exitosamente:\n",
            "  PYTHON 8/8/2015 http://example.com/image.png https://example.com/21 #55sr 194-229-8897 @y2tvblgzo 173.97.16.113\n",
            "0  12/12/2001 https://example.com/74 681-142-9071...                                                             \n",
            "1  bsanchez@icloud.com #3 54.220.113.226 http://e...                                                             \n",
            "2  363-275-5531 87.120.5.187 http://example.com/i...                                                             \n",
            "3  @h 140-453-8358 http://example.com/image.png 4...                                                             \n",
            "4  112-567-7656 http://example.com/34 FELICIDADES...                                                             \n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "import requests\n",
        "\n",
        "def check_library_versions():\n",
        "    \"\"\"\n",
        "    Imprime las versiones de las librerías pandas y requests.\n",
        "    \"\"\"\n",
        "    print(\"Versión de pandas:\", pd.__version__)\n",
        "    print(\"Versión de requests:\", requests.__version__)\n",
        "\n",
        "\n",
        "def load_dataset(url):\n",
        "    \"\"\"\n",
        "    Carga el dataset desde la URL proporcionada.\n",
        "\n",
        "    Args:\n",
        "        url (str): La URL del dataset.\n",
        "\n",
        "    Returns:\n",
        "        pandas.DataFrame: El dataset cargado como un DataFrame de Pandas.\n",
        "    \"\"\"\n",
        "    # Hacer una solicitud GET a la URL para obtener el contenido del archivo\n",
        "    response = requests.get(url)\n",
        "    \n",
        "    # Leer el contenido del archivo como un DataFrame de Pandas\n",
        "    dataset = pd.read_csv(url)\n",
        "    \n",
        "    return dataset\n",
        "\n",
        "\n",
        "# URL del dataset\n",
        "ruta = \"https://raw.githubusercontent.com/gabrielawad/talleresGoogleColab/main/Archivo_datos/regex/regex_1146443000.csv\"\n",
        "\n",
        "# Cargar el dataset\n",
        "dataset = load_dataset(ruta)\n",
        "\n",
        "# Verificar la lectura del dataset\n",
        "print(\"Dataset cargado exitosamente:\")\n",
        "print(dataset.head())\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4kpeP548VfWv"
      },
      "source": [
        "## Ejercicio 00\n",
        "\n",
        "Escriba un programa que lea el archivo de referencia y reporte cuántas direcciones de correo electrónico contiene en total y cuantas por cada dominio de correo electrónico.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "SMQWLfFhKsaO"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total de direcciones de correo electrónico: 28\n",
            "Direcciones por dominio:\n",
            "gmail.com: 5\n",
            "icloud.com: 6\n",
            "outlook.com: 6\n",
            "hotmail.com: 6\n",
            "yahoo.com: 5\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "\n",
        "def count_emails_by_domain(dataset):\n",
        "    \"\"\"\n",
        "    Cuenta cuántas direcciones de correo electrónico contiene en total el dataset\n",
        "    y cuántas pertenecen a cada dominio de correo electrónico.\n",
        "\n",
        "    Args:\n",
        "        dataset (pandas.DataFrame): El dataset que contiene las direcciones de correo electrónico.\n",
        "\n",
        "    Returns:\n",
        "        dict: Un diccionario que contiene el total de direcciones de correo electrónico y\n",
        "        la cantidad por cada dominio de correo electrónico.\n",
        "    \"\"\"\n",
        "    # Extraer todas las direcciones de correo electrónico utilizando una expresión regular\n",
        "    emails = re.findall(r'\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Z|a-z]{2,}\\b', dataset.to_string())\n",
        "\n",
        "    # Contar el total de direcciones de correo electrónico y la cantidad por cada dominio\n",
        "    total_emails = len(emails)\n",
        "    email_domains = {}\n",
        "    for email in emails:\n",
        "        domain = email.split('@')[1]\n",
        "        if domain in email_domains:\n",
        "            email_domains[domain] += 1\n",
        "        else:\n",
        "            email_domains[domain] = 1\n",
        "    \n",
        "    return {'total_emails': total_emails, 'emails_by_domain': email_domains}\n",
        "\n",
        "\n",
        "# Cargar el dataset\n",
        "ruta = \"https://raw.githubusercontent.com/gabrielawad/talleresGoogleColab/main/Archivo_datos/regex/regex_1146443000.csv\"\n",
        "dataset = pd.read_csv(ruta)\n",
        "\n",
        "# Contar las direcciones de correo electrónico por dominio\n",
        "email_info = count_emails_by_domain(dataset)\n",
        "\n",
        "# Imprimir resultados\n",
        "print(\"Total de direcciones de correo electrónico:\", email_info['total_emails'])\n",
        "print(\"Direcciones por dominio:\")\n",
        "for domain, count in email_info['emails_by_domain'].items():\n",
        "    print(f\"{domain}: {count}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AWpJFnkfZE8X"
      },
      "source": [
        "## Ejercicio 01\n",
        "Escriba un programa que lea el archivo de referencia y extraiga todos los números de teléfono válidos contenidos en él. Los números de teléfono válidos deben seguir el formato XXX-XXX-XXXX."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "CN9EHSJKK1Sn"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Números de teléfono válidos encontrados:\n",
            "681-142-9071\n",
            "363-275-5531\n",
            "140-453-8358\n",
            "112-567-7656\n",
            "483-723-2549\n",
            "477-559-7177\n",
            "504-901-6937\n",
            "573-119-9105\n",
            "422-528-9779\n",
            "311-779-5408\n",
            "255-542-7038\n",
            "639-832-1520\n",
            "145-419-6619\n",
            "911-833-3957\n",
            "157-939-6417\n",
            "729-799-7556\n",
            "178-740-9039\n",
            "275-439-2028\n",
            "361-706-6279\n",
            "338-851-8469\n",
            "160-715-3351\n",
            "733-517-6495\n",
            "592-666-2985\n",
            "102-888-3038\n",
            "121-287-2813\n",
            "338-910-8443\n",
            "586-939-8780\n",
            "126-265-9274\n",
            "570-275-5572\n",
            "793-170-8344\n",
            "324-708-4864\n",
            "637-156-9419\n",
            "930-907-7406\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "\n",
        "def extract_valid_phone_numbers(dataset):\n",
        "    \"\"\"\n",
        "    Extrae todos los números de teléfono válidos (formato XXX-XXX-XXXX) contenidos en el dataset.\n",
        "\n",
        "    Args:\n",
        "        dataset (pandas.DataFrame): El dataset que contiene los números de teléfono.\n",
        "\n",
        "    Returns:\n",
        "        list: Una lista de todos los números de teléfono válidos encontrados.\n",
        "    \"\"\"\n",
        "    # Expresión regular para buscar números de teléfono en formato XXX-XXX-XXXX\n",
        "    phone_regex = re.compile(r'\\b\\d{3}-\\d{3}-\\d{4}\\b')\n",
        "\n",
        "    # Buscar números de teléfono en el dataset y guardarlos en una lista\n",
        "    valid_phone_numbers = []\n",
        "    for row in dataset.itertuples(index=False):\n",
        "        for item in row:\n",
        "            matches = phone_regex.findall(str(item))\n",
        "            valid_phone_numbers.extend(matches)\n",
        "    \n",
        "    return valid_phone_numbers\n",
        "\n",
        "\n",
        "# Cargar el dataset\n",
        "ruta = \"https://raw.githubusercontent.com/gabrielawad/talleresGoogleColab/main/Archivo_datos/regex/regex_1146443000.csv\"\n",
        "dataset = pd.read_csv(ruta)\n",
        "\n",
        "# Extraer los números de teléfono válidos\n",
        "valid_phone_numbers = extract_valid_phone_numbers(dataset)\n",
        "\n",
        "# Imprimir los números de teléfono válidos encontrados\n",
        "print(\"Números de teléfono válidos encontrados:\")\n",
        "for phone_number in valid_phone_numbers:\n",
        "    print(phone_number)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0hEyKcvlaM1p"
      },
      "source": [
        "## Ejercicio 02\n",
        "\n",
        "Escriba un programa que lea el archivo de referencia y extraiga todas las fechas válidas contenidas. Las fechas válidas deben estar en formato \"DD/MM/AAAA\".\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "FifgJ7-EK2xH"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fechas válidas encontradas:\n",
            "12/12/2001\n",
            "12/10/1959\n",
            "19/11/2006\n",
            "10/12/1951\n",
            "25/10/2021\n",
            "28/12/1966\n",
            "18/10/1993\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "\n",
        "def extract_valid_dates(dataset):\n",
        "    \"\"\"\n",
        "    Extrae todas las fechas válidas (formato DD/MM/AAAA) contenidas en el dataset.\n",
        "\n",
        "    Args:\n",
        "        dataset (pandas.DataFrame): El dataset que contiene las fechas.\n",
        "\n",
        "    Returns:\n",
        "        list: Una lista de todas las fechas válidas encontradas.\n",
        "    \"\"\"\n",
        "    # Expresión regular para buscar fechas en formato DD/MM/AAAA\n",
        "    date_regex = re.compile(r'\\b\\d{2}/\\d{2}/\\d{4}\\b')\n",
        "\n",
        "    # Buscar fechas en el dataset y guardarlas en una lista\n",
        "    valid_dates = []\n",
        "    for row in dataset.itertuples(index=False):\n",
        "        for item in row:\n",
        "            matches = date_regex.findall(str(item))\n",
        "            valid_dates.extend(matches)\n",
        "    \n",
        "    return valid_dates\n",
        "\n",
        "\n",
        "# Cargar el dataset\n",
        "ruta = \"https://raw.githubusercontent.com/gabrielawad/talleresGoogleColab/main/Archivo_datos/regex/regex_1146443000.csv\"\n",
        "dataset = pd.read_csv(ruta)\n",
        "\n",
        "# Extraer las fechas válidas\n",
        "valid_dates = extract_valid_dates(dataset)\n",
        "\n",
        "# Imprimir las fechas válidas encontradas\n",
        "print(\"Fechas válidas encontradas:\")\n",
        "for date in valid_dates:\n",
        "    print(date)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qj50yF_aP_yM"
      },
      "source": [
        "## Ejercicio 03\n",
        "\n",
        "Escriba un programa que lea el archivo de referencia y extraiga todas las URLs válidas . Las URLs válidas deben comenzar con \"http://\" o \"https://\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "bdS-Re69K4Gr"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "URLs válidas encontradas:\n",
            "https://example.com/74\n",
            "http://example.com/image.jpg\n",
            "http://example.com/45\n",
            "http://example.com/image.png\n",
            "https://example.com/19\n",
            "http://example.com/image.png\n",
            "http://example.com/34\n",
            "http://example.com/image.jpg\n",
            "http://example.com/image.png\n",
            "https://example.com/62\n",
            "http://example.com/image.jpg\n",
            "https://example.com/41\n",
            "http://example.com/13\n",
            "http://example.com/image.gif\n",
            "http://example.com/50\n",
            "https://example.com/84\n",
            "http://example.com/image.png\n",
            "http://example.com/29\n",
            "http://example.com/image.png\n",
            "http://example.com/20\n",
            "http://example.com/image.jpg\n",
            "http://example.com/image.gif\n",
            "http://example.com/image.gif\n",
            "https://example.com/89\n",
            "http://example.com/image.png\n",
            "https://example.com/61\n",
            "http://example.com/image.jpg\n",
            "http://example.com/image.jpg\n",
            "http://example.com/9\n",
            "http://example.com/image.png\n",
            "http://example.com/image.jpg\n",
            "http://example.com/56\n",
            "http://example.com/52\n",
            "http://example.com/image.gif\n",
            "https://example.com/12\n",
            "http://example.com/image.jpg\n",
            "http://example.com/98\n",
            "http://example.com/image.png\n",
            "https://example.com/19\n",
            "http://example.com/image.jpg\n",
            "https://example.com/43\n",
            "http://example.com/image.png\n",
            "http://example.com/58\n",
            "http://example.com/image.png\n",
            "https://example.com/48\n",
            "http://example.com/image.gif\n",
            "http://example.com/image.gif\n",
            "http://example.com/image.png\n",
            "https://example.com/85\n",
            "http://example.com/image.gif\n",
            "http://example.com/37\n",
            "http://example.com/image.jpg\n",
            "https://example.com/68\n",
            "http://example.com/image.jpg\n",
            "http://example.com/image.gif\n",
            "http://example.com/96\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "\n",
        "def extract_valid_urls(dataset):\n",
        "    \"\"\"\n",
        "    Extrae todas las URLs válidas (comenzando con \"http://\" o \"https://\") contenidas en el dataset.\n",
        "\n",
        "    Args:\n",
        "        dataset (pandas.DataFrame): El dataset que contiene las URLs.\n",
        "\n",
        "    Returns:\n",
        "        list: Una lista de todas las URLs válidas encontradas.\n",
        "    \"\"\"\n",
        "    # Expresión regular para buscar URLs que comienzan con \"http://\" o \"https://\"\n",
        "    url_regex = re.compile(r'\\b(?:https?://)\\S+\\b')\n",
        "\n",
        "    # Buscar URLs en el dataset y guardarlas en una lista\n",
        "    valid_urls = []\n",
        "    for row in dataset.itertuples(index=False):\n",
        "        for item in row:\n",
        "            matches = url_regex.findall(str(item))\n",
        "            valid_urls.extend(matches)\n",
        "    \n",
        "    return valid_urls\n",
        "\n",
        "\n",
        "# Cargar el dataset\n",
        "ruta = \"https://raw.githubusercontent.com/gabrielawad/talleresGoogleColab/main/Archivo_datos/regex/regex_1146443000.csv\"\n",
        "dataset = pd.read_csv(ruta)\n",
        "\n",
        "# Extraer las URLs válidas\n",
        "valid_urls = extract_valid_urls(dataset)\n",
        "\n",
        "# Imprimir las URLs válidas encontradas\n",
        "print(\"URLs válidas encontradas:\")\n",
        "for url in valid_urls:\n",
        "    print(url)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4852xGV9QBaQ"
      },
      "source": [
        "## Ejercicio 04\n",
        "\n",
        "Escriba un programa que lea el archivo de referencia y extraiga todas las direcciones IP válidas. Las direcciones IP válidas deben seguir el formato \"XXX.XXX.XXX.XXX\", donde cada parte puede tener uno, dos o tres dígitos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "IUhNlDkgK5l_"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Direcciones IP válidas encontradas:\n",
            "54.220.113.226\n",
            "87.120.5.187\n",
            "42.193.145.126\n",
            "125.198.111.151\n",
            "127.138.30.224\n",
            "145.62.106.69\n",
            "126.2.50.27\n",
            "180.49.53.21\n",
            "225.196.187.112\n",
            "4.194.94.194\n",
            "86.221.6.174\n",
            "8.62.36.226\n",
            "142.95.12.63\n",
            "189.246.188.179\n",
            "152.75.39.67\n",
            "94.83.15.80\n",
            "179.155.220.147\n",
            "2.40.224.250\n",
            "219.204.108.13\n",
            "251.242.92.244\n",
            "12.30.66.144\n",
            "220.62.13.47\n",
            "25.197.102.175\n",
            "25.45.48.252\n",
            "61.234.47.170\n",
            "61.45.151.204\n",
            "243.143.223.142\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "\n",
        "def extract_valid_ips(dataset):\n",
        "    \"\"\"\n",
        "    Extrae todas las direcciones IP válidas (formato XXX.XXX.XXX.XXX) contenidas en el dataset.\n",
        "\n",
        "    Args:\n",
        "        dataset (pandas.DataFrame): El dataset que contiene las direcciones IP.\n",
        "\n",
        "    Returns:\n",
        "        list: Una lista de todas las direcciones IP válidas encontradas.\n",
        "    \"\"\"\n",
        "    # Expresión regular para buscar direcciones IP en formato XXX.XXX.XXX.XXX\n",
        "    ip_regex = re.compile(r'\\b(?:\\d{1,3}\\.){3}\\d{1,3}\\b')\n",
        "\n",
        "    # Buscar direcciones IP en el dataset y guardarlas en una lista\n",
        "    valid_ips = []\n",
        "    for row in dataset.itertuples(index=False):\n",
        "        for item in row:\n",
        "            matches = ip_regex.findall(str(item))\n",
        "            valid_ips.extend(matches)\n",
        "    \n",
        "    return valid_ips\n",
        "\n",
        "\n",
        "# Cargar el dataset\n",
        "ruta = \"https://raw.githubusercontent.com/gabrielawad/talleresGoogleColab/main/Archivo_datos/regex/regex_1146443000.csv\"\n",
        "dataset = pd.read_csv(ruta)\n",
        "\n",
        "# Extraer las direcciones IP válidas\n",
        "valid_ips = extract_valid_ips(dataset)\n",
        "\n",
        "# Imprimir las direcciones IP válidas encontradas\n",
        "print(\"Direcciones IP válidas encontradas:\")\n",
        "for ip in valid_ips:\n",
        "    print(ip)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ztj4sS1hQDtc"
      },
      "source": [
        "## Ejercicio 05\n",
        "\n",
        "Escriba un programa que lea el archivo de referencia y extraiga todos los hashtags. Los hashtags deben comenzar con el símbolo \"#\" y pueden contener letras, números y guiones bajos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "GA_5dcsnK7Hr"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hashtags encontrados:\n",
            "#3\n",
            "#prkbqpxa\n",
            "#mx8\n",
            "#93r6nq\n",
            "#94x_1mazry\n",
            "#99hhqfpg1\n",
            "#v8knn\n",
            "#3ck7\n",
            "#e0td6ir72\n",
            "#f_ux4_n95\n",
            "#_ir5ttq\n",
            "#7cl\n",
            "#9giemu\n",
            "#0g6s\n",
            "#6i\n",
            "#u6j2if\n",
            "#pr41hu\n",
            "#1c\n",
            "#3lc8894bb\n",
            "#czc8nth23d\n",
            "#r45vd4c\n",
            "#fi10v8ba7\n",
            "#uo3f\n",
            "#uo4\n",
            "#4\n",
            "#a0gt\n",
            "#97j0h4\n",
            "#8rc1fz1tf\n",
            "#x1bloy\n",
            "#dp\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "\n",
        "def extract_hashtags(dataset):\n",
        "    \"\"\"\n",
        "    Extrae todos los hashtags contenidos en el dataset.\n",
        "\n",
        "    Args:\n",
        "        dataset (pandas.DataFrame): El dataset que contiene los hashtags.\n",
        "\n",
        "    Returns:\n",
        "        list: Una lista de todos los hashtags encontrados.\n",
        "    \"\"\"\n",
        "    # Expresión regular para buscar hashtags\n",
        "    hashtag_regex = re.compile(r'#\\w+')\n",
        "\n",
        "    # Buscar hashtags en el dataset y guardarlos en una lista\n",
        "    hashtags = []\n",
        "    for row in dataset.itertuples(index=False):\n",
        "        for item in row:\n",
        "            matches = hashtag_regex.findall(str(item))\n",
        "            hashtags.extend(matches)\n",
        "    \n",
        "    return hashtags\n",
        "\n",
        "\n",
        "# Cargar el dataset\n",
        "ruta = \"https://raw.githubusercontent.com/gabrielawad/talleresGoogleColab/main/Archivo_datos/regex/regex_1146443000.csv\"\n",
        "dataset = pd.read_csv(ruta)\n",
        "\n",
        "# Extraer los hashtags\n",
        "hashtags = extract_hashtags(dataset)\n",
        "\n",
        "# Imprimir los hashtags encontrados\n",
        "print(\"Hashtags encontrados:\")\n",
        "for hashtag in hashtags:\n",
        "    print(hashtag)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hATd-LMUQGP_"
      },
      "source": [
        "## Ejercicio 06\n",
        "\n",
        "Escriba un programa que lea el archivo de referencia y extraiga todos los nombres de usuario válidos de X. Los nombres de usuario válidos deben comenzar con el símbolo \"@\" y pueden contener letras, números y guiones bajos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "2JuhtZdmK8tO"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Nombres de usuario válidos encontrados:\n",
            "@l\n",
            "@581kn11\n",
            "@h\n",
            "@_2gs9\n",
            "@88me_irie\n",
            "@bs80jef4b_\n",
            "@11wl3uewh5\n",
            "@rei9ank055\n",
            "@h99_\n",
            "@zd43nc_sxd\n",
            "@eqwl4\n",
            "@c\n",
            "@r5m0\n",
            "@14d\n",
            "@ajhown\n",
            "@ia_7q55\n",
            "@bih1v\n",
            "@7xz92t\n",
            "@84ot\n",
            "@ng6vs08i\n",
            "@50guc3_\n",
            "@k36p1cn\n",
            "@t719d9\n",
            "@_ms1x\n",
            "@ao7epc9\n",
            "@3p8sj16cpj\n",
            "@bn\n",
            "@9e4\n",
            "@he6hr\n",
            "@zp7qa\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "\n",
        "def extract_valid_usernames(dataset):\n",
        "    \"\"\"\n",
        "    Extrae todos los nombres de usuario válidos (comenzando con \"@\" y pueden contener letras, números y guiones bajos)\n",
        "    contenidos en el dataset.\n",
        "\n",
        "    Args:\n",
        "        dataset (pandas.DataFrame): El dataset que contiene los nombres de usuario.\n",
        "\n",
        "    Returns:\n",
        "        list: Una lista de todos los nombres de usuario válidos encontrados.\n",
        "    \"\"\"\n",
        "    # Expresión regular ajustada para buscar nombres de usuario válidos\n",
        "    username_regex = re.compile(r'\\B@\\w+\\b')\n",
        "\n",
        "    # Buscar nombres de usuario en el dataset y guardarlos en una lista\n",
        "    valid_usernames = []\n",
        "    for row in dataset.itertuples(index=False):\n",
        "        for item in row:\n",
        "            matches = username_regex.findall(str(item))\n",
        "            valid_usernames.extend(matches)\n",
        "    \n",
        "    return valid_usernames\n",
        "\n",
        "\n",
        "# Cargar el dataset\n",
        "ruta = \"https://raw.githubusercontent.com/gabrielawad/talleresGoogleColab/main/Archivo_datos/regex/regex_1146443000.csv\"\n",
        "dataset = pd.read_csv(ruta)\n",
        "\n",
        "# Extraer los nombres de usuario válidos\n",
        "valid_usernames = extract_valid_usernames(dataset)\n",
        "\n",
        "# Imprimir los nombres de usuario válidos encontrados\n",
        "print(\"Nombres de usuario válidos encontrados:\")\n",
        "for username in valid_usernames:\n",
        "    print(username)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZNOMGOKfQHkc"
      },
      "source": [
        "## Ejercicio 07\n",
        "\n",
        "Escriba un programa que lea el archivo de referencia y extraiga todas las URLs de imágenes válidas. Las URLs de imágenes válidas pueden terminar en extensiones comunes como \".jpg\", \".png\" o \".gif\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "RXmZuoc_K-Uw"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "URLs de imágenes válidas encontradas:\n",
            "http://example.com/image.jpg\n",
            "http://example.com/image.png\n",
            "http://example.com/image.png\n",
            "http://example.com/image.jpg\n",
            "http://example.com/image.png\n",
            "http://example.com/image.jpg\n",
            "http://example.com/image.gif\n",
            "http://example.com/image.png\n",
            "http://example.com/image.png\n",
            "http://example.com/image.jpg\n",
            "http://example.com/image.gif\n",
            "http://example.com/image.gif\n",
            "http://example.com/image.png\n",
            "http://example.com/image.jpg\n",
            "http://example.com/image.jpg\n",
            "http://example.com/image.png\n",
            "http://example.com/image.jpg\n",
            "http://example.com/image.gif\n",
            "http://example.com/image.jpg\n",
            "http://example.com/image.png\n",
            "http://example.com/image.jpg\n",
            "http://example.com/image.png\n",
            "http://example.com/image.png\n",
            "http://example.com/image.gif\n",
            "http://example.com/image.gif\n",
            "http://example.com/image.png\n",
            "http://example.com/image.gif\n",
            "http://example.com/image.jpg\n",
            "http://example.com/image.jpg\n",
            "http://example.com/image.gif\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "\n",
        "def extract_valid_image_urls(dataset):\n",
        "    \"\"\"\n",
        "    Extrae todas las URLs de imágenes válidas (terminadas en extensiones comunes como \".jpg\", \".png\" o \".gif\")\n",
        "    contenidas en el dataset.\n",
        "\n",
        "    Args:\n",
        "        dataset (pandas.DataFrame): El dataset que contiene las URLs de imágenes.\n",
        "\n",
        "    Returns:\n",
        "        list: Una lista de todas las URLs de imágenes válidas encontradas.\n",
        "    \"\"\"\n",
        "    # Expresión regular para buscar URLs de imágenes válidas\n",
        "    image_url_regex = re.compile(r'\\bhttps?://\\S+\\.(?:jpg|png|gif)\\b')\n",
        "\n",
        "    # Buscar URLs de imágenes en el dataset y guardarlas en una lista\n",
        "    valid_image_urls = []\n",
        "    for row in dataset.itertuples(index=False):\n",
        "        for item in row:\n",
        "            matches = image_url_regex.findall(str(item))\n",
        "            valid_image_urls.extend(matches)\n",
        "    \n",
        "    return valid_image_urls\n",
        "\n",
        "\n",
        "# Cargar el dataset\n",
        "ruta = \"https://raw.githubusercontent.com/gabrielawad/talleresGoogleColab/main/Archivo_datos/regex/regex_1146443000.csv\"\n",
        "dataset = pd.read_csv(ruta)\n",
        "\n",
        "# Extraer las URLs de imágenes válidas\n",
        "valid_image_urls = extract_valid_image_urls(dataset)\n",
        "\n",
        "# Imprimir las URLs de imágenes válidas encontradas\n",
        "print(\"URLs de imágenes válidas encontradas:\")\n",
        "for image_url in valid_image_urls:\n",
        "    print(image_url)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k1SR_Y-RQJC1"
      },
      "source": [
        "## Ejercicio 08\n",
        "\n",
        "Escriba un programa que lea el archivo de referencia y extraiga los números de los documentos de identidad. Un número de documento de identidad válido es una cadena de siete números seguidos que no contiene comas ni puntos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "-yFIOR5mLAal"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Números de documentos de identidad válidos encontrados:\n",
            "2170167\n",
            "8881133\n",
            "4006873\n",
            "5852594\n",
            "0332444\n",
            "5998339\n",
            "4824913\n",
            "7227667\n",
            "0235124\n",
            "6502801\n",
            "1831573\n",
            "7508113\n",
            "6731713\n",
            "0474308\n",
            "7961657\n",
            "5255039\n",
            "9284882\n",
            "2964886\n",
            "9219538\n",
            "0616371\n",
            "7650049\n",
            "5765875\n",
            "1259944\n",
            "7032827\n",
            "5724845\n",
            "1383196\n",
            "2072191\n",
            "7455805\n",
            "7910614\n",
            "2301230\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "\n",
        "def extract_valid_id_numbers(dataset):\n",
        "    \"\"\"\n",
        "    Extrae todos los números de documentos de identidad válidos (cadenas de siete números seguidos que no contienen comas ni puntos)\n",
        "    contenidos en el dataset.\n",
        "\n",
        "    Args:\n",
        "        dataset (pandas.DataFrame): El dataset que contiene los números de documentos de identidad.\n",
        "\n",
        "    Returns:\n",
        "        list: Una lista de todos los números de documentos de identidad válidos encontrados.\n",
        "    \"\"\"\n",
        "    # Expresión regular para buscar números de documentos de identidad válidos\n",
        "    id_number_regex = re.compile(r'\\b\\d{7}\\b')\n",
        "\n",
        "    # Buscar números de documentos de identidad en el dataset y guardarlos en una lista\n",
        "    valid_id_numbers = []\n",
        "    for row in dataset.itertuples(index=False):\n",
        "        for item in row:\n",
        "            matches = id_number_regex.findall(str(item))\n",
        "            valid_id_numbers.extend(matches)\n",
        "    \n",
        "    return valid_id_numbers\n",
        "\n",
        "\n",
        "# Cargar el dataset\n",
        "ruta = \"https://raw.githubusercontent.com/gabrielawad/talleresGoogleColab/main/Archivo_datos/regex/regex_1146443000.csv\"\n",
        "dataset = pd.read_csv(ruta)\n",
        "\n",
        "# Extraer los números de documentos de identidad válidos\n",
        "valid_id_numbers = extract_valid_id_numbers(dataset)\n",
        "\n",
        "# Imprimir los números de documentos de identidad válidos encontrados\n",
        "print(\"Números de documentos de identidad válidos encontrados:\")\n",
        "for id_number in valid_id_numbers:\n",
        "    print(id_number)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VlxrpT47QKdX"
      },
      "source": [
        "## Ejercicio 09\n",
        "\n",
        "Escriba un programa que lea el archivo de referencia y reporte cuántas palabras en mayúsculas contiene y cuántas veces aparece cada palabra.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "3tJqbO68LB5C"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Palabras en mayúsculas encontradas y su frecuencia:\n",
            "CASA: 4\n",
            "PYTHON: 2\n",
            "FELICIDADES: 6\n",
            "AMOR: 2\n",
            "EJEMPLO: 2\n",
            "FAMILIA: 4\n",
            "PAZ: 4\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "from collections import Counter\n",
        "\n",
        "def count_uppercase_words(dataset):\n",
        "    \"\"\"\n",
        "    Cuenta cuántas palabras en mayúsculas contiene el dataset y cuántas veces aparece cada una.\n",
        "\n",
        "    Args:\n",
        "        dataset (pandas.DataFrame): El dataset que contiene las palabras en mayúsculas.\n",
        "\n",
        "    Returns:\n",
        "        dict: Un diccionario que contiene las palabras en mayúsculas como clave y su frecuencia como valor.\n",
        "    \"\"\"\n",
        "    # Expresión regular para buscar palabras en mayúsculas\n",
        "    uppercase_word_regex = re.compile(r'\\b[A-Z]+\\b')\n",
        "\n",
        "    # Buscar palabras en mayúsculas en el dataset y contar su frecuencia\n",
        "    all_words = ' '.join(dataset.apply(lambda x: ' '.join(map(str, x)), axis=1))\n",
        "    uppercase_words = uppercase_word_regex.findall(all_words)\n",
        "    return dict(Counter(uppercase_words))\n",
        "\n",
        "\n",
        "# Cargar el dataset\n",
        "ruta = \"https://raw.githubusercontent.com/gabrielawad/talleresGoogleColab/main/Archivo_datos/regex/regex_1146443000.csv\"\n",
        "dataset = pd.read_csv(ruta)\n",
        "\n",
        "# Contar las palabras en mayúsculas y su frecuencia\n",
        "uppercase_words_count = count_uppercase_words(dataset)\n",
        "\n",
        "# Imprimir el resultado\n",
        "print(\"Palabras en mayúsculas encontradas y su frecuencia:\")\n",
        "for word, count in uppercase_words_count.items():\n",
        "    print(f\"{word}: {count}\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
